{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyPejUwuQGxBKujKac5dNvBm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "656463f343f84978a56d2d110e2bcc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2408b16bd895429a8f01922765589f49",
              "IPY_MODEL_ad9332ddfccb4a01b8c22dd57c6d83eb",
              "IPY_MODEL_9243da87250d4c8bbe6fee3449c53813"
            ],
            "layout": "IPY_MODEL_61a180e874cb482c8054e04290f0d589"
          }
        },
        "2408b16bd895429a8f01922765589f49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3ea241d9df48bba640cb3e71f220a7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9f3d721d83f74f399e9f4afe47b4ab74",
            "value": "Map:‚Äá100%"
          }
        },
        "ad9332ddfccb4a01b8c22dd57c6d83eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f55f84b9a746b092e2c3583ac76a70",
            "max": 872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a15799368302445489ae4f71af19c53e",
            "value": 872
          }
        },
        "9243da87250d4c8bbe6fee3449c53813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122f072d3cba4a4e99d98e9f1139599a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8a710cc736da45c08db5e542976bc9ce",
            "value": "‚Äá872/872‚Äá[00:00&lt;00:00,‚Äá1187.87‚Äáexamples/s]"
          }
        },
        "61a180e874cb482c8054e04290f0d589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f3ea241d9df48bba640cb3e71f220a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3d721d83f74f399e9f4afe47b4ab74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "63f55f84b9a746b092e2c3583ac76a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a15799368302445489ae4f71af19c53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "122f072d3cba4a4e99d98e9f1139599a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a710cc736da45c08db5e542976bc9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulrukhsorakhmadjanova/ml.ai/blob/main/task1_uzcosmos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC6xNAsGg_WS",
        "outputId": "cbdcf715-039c-43e8-8ea8-54129ebb33df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (0.22.2)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb) (8.3.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.11.10)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb) (2.42.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n"
          ]
        }
      ],
      "source": [
        "# Colab: install dependencies\n",
        "!pip install --upgrade pip\n",
        "!pip install transformers datasets evaluate scikit-learn sentencepiece wandb tensorboard\n",
        "# Optional: accelerate for mixed-precision/higher perf\n",
        "!pip install -q accelerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#login to wandb to track experiments\n",
        "import os\n",
        "use_wandb = False  # set True if you want to use wandb\n",
        "if use_wandb:\n",
        "    import wandb\n",
        "    wandb.login()  # follow prompt\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "else:\n",
        "    os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
      ],
      "metadata": {
        "id": "_t0nQWALhM7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_py = \"\"\"\n",
        "\\\"\"\"\n",
        "train.py ‚Äî Fine-tune BERT (bert-base-uncased) on SST-2 sentiment classification.\n",
        "\n",
        "‚úÖ Requirements satisfied:\n",
        "1. Data Preparation via Hugging Face datasets & tokenizer\n",
        "2. Model Fine-Tuning with Trainer API\n",
        "3. Evaluation: Accuracy + F1 + classification report + confusion matrix\n",
        "4. Organized, modular, readable code\n",
        "5. Deliverables-ready: logs, model saving, optional W&B/TensorBoard\n",
        "6. Bonus: Early stopping, model checkpointing, gradient clipping, LR scheduler, custom training loop option\n",
        "\n",
        "Author: Gulrukhsor Akhmadjanova\n",
        "\\\"\"\"\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "from transformers import (\n",
        "    BertTokenizerFast,\n",
        "    BertForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    EarlyStoppingCallback,\n",
        "    DataCollatorWithPadding,\n",
        "    set_seed,\n",
        ")\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "\n",
        "\n",
        "# ---------- Compute metrics ----------\n",
        "def compute_metrics(pred):\n",
        "    \\\"\"\"Compute accuracy and macro F1 using the evaluate library.\\\"\"\"\n",
        "    preds = pred.predictions\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    y_pred = np.argmax(preds, axis=1)\n",
        "    y_true = pred.label_ids\n",
        "\n",
        "    accuracy = (y_pred == y_true).mean()\n",
        "    f1_metric = evaluate.load(\\\"f1\\\")\n",
        "    f1_score = f1_metric.compute(predictions=y_pred, references=y_true, average=\\\"macro\\\")[\\\"f1\\\"]\n",
        "    return {\\\"accuracy\\\": float(accuracy), \\\"f1_macro\\\": float(f1_score)}\n",
        "\n",
        "\n",
        "# ---------- Argument parser ----------\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description=\\\"Fine-tune BERT on SST-2 dataset\\\")\n",
        "    parser.add_argument(\\\"--model_name\\\", type=str, default=\\\"bert-base-uncased\\\")\n",
        "    parser.add_argument(\\\"--output_dir\\\", type=str, default=\\\"./sst2_outputs\\\")\n",
        "    parser.add_argument(\\\"--epochs\\\", type=int, default=3)\n",
        "    parser.add_argument(\\\"--per_device_train_batch_size\\\", type=int, default=8)\n",
        "    parser.add_argument(\\\"--per_device_eval_batch_size\\\", type=int, default=32)\n",
        "    parser.add_argument(\\\"--lr\\\", type=float, default=2e-5)\n",
        "    parser.add_argument(\\\"--weight_decay\\\", type=float, default=0.01)\n",
        "    parser.add_argument(\\\"--max_length\\\", type=int, default=128)\n",
        "    parser.add_argument(\\\"--seed\\\", type=int, default=42)\n",
        "    parser.add_argument(\\\"--save_total_limit\\\", type=int, default=3)\n",
        "    parser.add_argument(\\\"--logging_steps\\\", type=int, default=200)\n",
        "    parser.add_argument(\\\"--use_custom_loop\\\", action=\\\"store_true\\\", help=\\\"Run custom PyTorch loop instead of Trainer\\\")\n",
        "    parser.add_argument(\\\"--push_to_hub\\\", action=\\\"store_true\\\", help=\\\"Push best model to Hugging Face Hub\\\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "# ---------- Main training ----------\n",
        "def main():\n",
        "    args = parse_args()\n",
        "    set_seed(args.seed)\n",
        "    os.makedirs(args.output_dir, exist_ok=True)\n",
        "\n",
        "    # Load SST-2 dataset\n",
        "    dataset = load_dataset(\\\"glue\\\", \\\"sst2\\\")\n",
        "    print(\\\"üìö Dataset loaded:\\\")\n",
        "    print({split: len(dataset[split]) for split in dataset.keys()})\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(args.model_name)\n",
        "    model = BertForSequenceClassification.from_pretrained(args.model_name, num_labels=2)\n",
        "\n",
        "    # Preprocessing\n",
        "    def preprocess(examples):\n",
        "        return tokenizer(examples[\\\"sentence\\\"], truncation=True, padding=False, max_length=args.max_length)\n",
        "\n",
        "    tokenized = dataset.map(preprocess, batched=True, remove_columns=[\\\"sentence\\\", \\\"idx\\\"] if \\\"idx\\\" in dataset[\\\"train\\\"].column_names else [\\\"sentence\\\"])\n",
        "\n",
        "    # Data collator\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "    # Training arguments\n",
        "    timestamp = datetime.now().strftime(\\\"%Y%m%d-%H%M%S\\\")\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=os.path.join(args.output_dir, timestamp),\n",
        "        eval_strategy=\\\"epoch\\\",\n",
        "        save_strategy=\\\"epoch\\\",\n",
        "        learning_rate=args.lr,\n",
        "        per_device_train_batch_size=args.per_device_train_batch_size,\n",
        "        per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
        "        num_train_epochs=args.epochs,\n",
        "        weight_decay=args.weight_decay,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\\\"f1_macro\\\",\n",
        "        greater_is_better=True,\n",
        "        save_total_limit=args.save_total_limit,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "        logging_dir=os.path.join(args.output_dir, \\\"logs\\\"),\n",
        "        logging_strategy=\\\"steps\\\",\n",
        "        logging_steps=args.logging_steps,\n",
        "        report_to=[\\\"tensorboard\\\"],\n",
        "        run_name=f\\\"sst2-bert-{timestamp}\\\",\n",
        "    )\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized[\\\"train\\\"],\n",
        "        eval_dataset=tokenized[\\\"validation\\\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    if args.use_custom_loop:\n",
        "        custom_train_loop(model, tokenized[\\\"train\\\"], tokenized[\\\"validation\\\"], tokenizer, args)\n",
        "    else:\n",
        "        trainer.train()\n",
        "        metrics = trainer.evaluate()\n",
        "        print(\\\"\\\\nüìä Validation Metrics:\\\", metrics)\n",
        "\n",
        "        # Save best model\n",
        "        best_dir = os.path.join(training_args.output_dir, \\\"best_model\\\")\n",
        "        trainer.save_model(best_dir)\n",
        "        tokenizer.save_pretrained(best_dir)\n",
        "        print(f\\\"‚úÖ Model saved at: {best_dir}\\\")\n",
        "\n",
        "        # Detailed evaluation\n",
        "        preds_output = trainer.predict(tokenized[\\\"validation\\\"])\n",
        "        preds = preds_output.predictions\n",
        "        if isinstance(preds, tuple):\n",
        "            preds = preds[0]\n",
        "        y_pred = np.argmax(preds, axis=1)\n",
        "        y_true = preds_output.label_ids\n",
        "\n",
        "        print(\\\"\\\\nClassification Report:\\\")\n",
        "        print(classification_report(y_true, y_pred, digits=4))\n",
        "        print(\\\"\\\\nConfusion Matrix:\\\")\n",
        "        print(confusion_matrix(y_true, y_pred))\n",
        "\n",
        "    if args.push_to_hub:\n",
        "        trainer.push_to_hub()\n",
        "\n",
        "\n",
        "# ---------- Optional Custom Loop ----------\n",
        "def custom_train_loop(model, train_dataset, val_dataset, tokenizer, args):\n",
        "    \\\"\"\"\n",
        "    Custom training loop for bonus points (manual PyTorch training).\n",
        "    \\\"\"\"\n",
        "    from torch.utils.data import DataLoader\n",
        "    from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "    device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\n",
        "    model.to(device)\n",
        "\n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=args.per_device_train_batch_size, shuffle=True, collate_fn=data_collator)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=args.per_device_eval_batch_size, collate_fn=data_collator)\n",
        "\n",
        "    optimizer = AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "    total_steps = len(train_loader) * args.epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.06 * total_steps), num_training_steps=total_steps)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "    early_stop_patience = 2\n",
        "\n",
        "    f1_metric = evaluate.load(\\\"f1\\\")\n",
        "\n",
        "    for epoch in range(args.epochs):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            outputs = model(**batch)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            optimizer.zero_grad()\n",
        "            total_loss += loss.item()\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        all_preds, all_labels = [], []\n",
        "        for batch in val_loader:\n",
        "            labels = batch[\\\"labels\\\"]\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            with torch.no_grad():\n",
        "                logits = model(**batch).logits\n",
        "            all_preds.append(logits.cpu().numpy())\n",
        "            all_labels.append(labels.numpy())\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        y_pred = np.argmax(all_preds, axis=1)\n",
        "        acc = (y_pred == all_labels).mean()\n",
        "        f1_score = f1_metric.compute(predictions=y_pred, references=all_labels, average=\\\"macro\\\")[\\\"f1\\\"]\n",
        "\n",
        "        print(f\\\"Epoch {epoch+1}/{args.epochs} | Train loss: {avg_train_loss:.4f} | Val acc: {acc:.4f} | Val f1: {f1_score:.4f}\\\")\n",
        "\n",
        "        # Early stopping\n",
        "        if f1_score > best_f1:\n",
        "            best_f1 = f1_score\n",
        "            patience_counter = 0\n",
        "            save_dir = os.path.join(args.output_dir, \\\"custom_best\\\")\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "            model.save_pretrained(save_dir)\n",
        "            tokenizer.save_pretrained(save_dir)\n",
        "            print(f\\\"‚úÖ New best F1: {best_f1:.4f} -> Model saved to {save_dir}\\\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= early_stop_patience:\n",
        "                print(\\\"‚èπÔ∏è Early stopping triggered.\\\")\n",
        "                break\n",
        "\n",
        "\n",
        "if __name__ == \\\"__main__\\\":\n",
        "    main()\n",
        "\"\"\"\n",
        "with open(\"train.py\", \"w\") as f:\n",
        "    f.write(train_py)\n",
        "print(\"‚úÖ train.py created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpIY2dehjP4p",
        "outputId": "bc9c20e7-cc2d-4baf-bf64-157bd6779164"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ train.py created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: In Colab free GPU you may need to reduce per_device_train_batch_size to 8 or 4.\n",
        "!python train.py --output_dir ./sst2_outputs --epochs 3 --per_device_train_batch_size 16 --per_device_eval_batch_size 64 --lr 2e-5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jETJu6MZhtTp",
        "outputId": "d752706c-3275-4ab6-eb10-c23aff8ef0ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-10-30 22:58:59.682201: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761865139.701750    9474 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761865139.707641    9474 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761865139.723274    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761865139.723302    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761865139.723309    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761865139.723312    9474 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "üìö Dataset loaded:\n",
            "{'train': 67349, 'validation': 872, 'test': 1821}\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map: 100% 1821/1821 [00:00<00:00, 11316.93 examples/s]\n",
            "/content/train.py:117: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "{'loss': 0.404, 'grad_norm': 4.247182846069336, 'learning_rate': 1.968487727632621e-05, 'epoch': 0.05}\n",
            "{'loss': 0.2874, 'grad_norm': 11.342479705810547, 'learning_rate': 1.9368171021377674e-05, 'epoch': 0.1}\n",
            "{'loss': 0.2919, 'grad_norm': 3.763550281524658, 'learning_rate': 1.9051464766429136e-05, 'epoch': 0.14}\n",
            "{'loss': 0.2382, 'grad_norm': 8.38266372680664, 'learning_rate': 1.8734758511480605e-05, 'epoch': 0.19}\n",
            "{'loss': 0.2561, 'grad_norm': 16.561630249023438, 'learning_rate': 1.8418052256532067e-05, 'epoch': 0.24}\n",
            "{'loss': 0.2176, 'grad_norm': 10.507875442504883, 'learning_rate': 1.8101346001583533e-05, 'epoch': 0.29}\n",
            "{'loss': 0.214, 'grad_norm': 16.09060287475586, 'learning_rate': 1.7784639746635e-05, 'epoch': 0.33}\n",
            "{'loss': 0.2189, 'grad_norm': 1.0908855199813843, 'learning_rate': 1.746793349168646e-05, 'epoch': 0.38}\n",
            "{'loss': 0.2103, 'grad_norm': 17.285686492919922, 'learning_rate': 1.7151227236737926e-05, 'epoch': 0.43}\n",
            "{'loss': 0.2135, 'grad_norm': 18.260353088378906, 'learning_rate': 1.683452098178939e-05, 'epoch': 0.48}\n",
            "{'loss': 0.2117, 'grad_norm': 10.950348854064941, 'learning_rate': 1.6517814726840857e-05, 'epoch': 0.52}\n",
            "{'loss': 0.1911, 'grad_norm': 3.4855082035064697, 'learning_rate': 1.6201108471892323e-05, 'epoch': 0.57}\n",
            "{'loss': 0.1992, 'grad_norm': 6.310308456420898, 'learning_rate': 1.5884402216943785e-05, 'epoch': 0.62}\n",
            "{'loss': 0.2006, 'grad_norm': 5.351633071899414, 'learning_rate': 1.556769596199525e-05, 'epoch': 0.67}\n",
            "{'loss': 0.2135, 'grad_norm': 14.988118171691895, 'learning_rate': 1.5250989707046716e-05, 'epoch': 0.71}\n",
            "{'loss': 0.2011, 'grad_norm': 11.822001457214355, 'learning_rate': 1.493428345209818e-05, 'epoch': 0.76}\n",
            "{'loss': 0.1852, 'grad_norm': 8.327995300292969, 'learning_rate': 1.4617577197149643e-05, 'epoch': 0.81}\n",
            "{'loss': 0.186, 'grad_norm': 3.896007776260376, 'learning_rate': 1.430087094220111e-05, 'epoch': 0.86}\n",
            "{'loss': 0.1779, 'grad_norm': 6.254062175750732, 'learning_rate': 1.3984164687252574e-05, 'epoch': 0.9}\n",
            "{'loss': 0.1749, 'grad_norm': 16.415103912353516, 'learning_rate': 1.366745843230404e-05, 'epoch': 0.95}\n",
            "{'loss': 0.1753, 'grad_norm': 31.212554931640625, 'learning_rate': 1.3350752177355504e-05, 'epoch': 1.0}\n",
            " 33% 4209/12630 [04:52<11:05, 12.65it/s]\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 21% 3/14 [00:00<00:00, 29.53it/s]\u001b[A\n",
            " 43% 6/14 [00:00<00:00, 24.29it/s]\u001b[A\n",
            " 64% 9/14 [00:00<00:00, 22.82it/s]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.27916622161865234, 'eval_accuracy': 0.9151376146788991, 'eval_f1_macro': 0.9150084032727982, 'eval_runtime': 1.1733, 'eval_samples_per_second': 743.193, 'eval_steps_per_second': 11.932, 'epoch': 1.0}\n",
            " 33% 4210/12630 [04:53<11:05, 12.65it/s]\n",
            "100% 14/14 [00:01<00:00, 21.86it/s]\u001b[A\n",
            "{'loss': 0.1224, 'grad_norm': 15.603553771972656, 'learning_rate': 1.3034045922406968e-05, 'epoch': 1.05}\n",
            "{'loss': 0.1248, 'grad_norm': 19.74728775024414, 'learning_rate': 1.2717339667458433e-05, 'epoch': 1.09}\n",
            "{'loss': 0.1105, 'grad_norm': 0.40395188331604004, 'learning_rate': 1.2400633412509897e-05, 'epoch': 1.14}\n",
            "{'loss': 0.1383, 'grad_norm': 0.4005282521247864, 'learning_rate': 1.2083927157561364e-05, 'epoch': 1.19}\n",
            "{'loss': 0.1191, 'grad_norm': 0.3140071630477905, 'learning_rate': 1.1767220902612828e-05, 'epoch': 1.24}\n",
            "{'loss': 0.1156, 'grad_norm': 0.1306520700454712, 'learning_rate': 1.1450514647664292e-05, 'epoch': 1.28}\n",
            "{'loss': 0.1209, 'grad_norm': 6.358180999755859, 'learning_rate': 1.1133808392715757e-05, 'epoch': 1.33}\n",
            "{'loss': 0.1032, 'grad_norm': 0.7352614402770996, 'learning_rate': 1.0817102137767221e-05, 'epoch': 1.38}\n",
            "{'loss': 0.1299, 'grad_norm': 16.187334060668945, 'learning_rate': 1.0500395882818687e-05, 'epoch': 1.43}\n",
            "{'loss': 0.1133, 'grad_norm': 0.6814327239990234, 'learning_rate': 1.018368962787015e-05, 'epoch': 1.47}\n",
            "{'loss': 0.1084, 'grad_norm': 13.838926315307617, 'learning_rate': 9.866983372921616e-06, 'epoch': 1.52}\n",
            "{'loss': 0.1111, 'grad_norm': 0.3396858274936676, 'learning_rate': 9.55027711797308e-06, 'epoch': 1.57}\n",
            "{'loss': 0.1445, 'grad_norm': 0.35328182578086853, 'learning_rate': 9.233570863024545e-06, 'epoch': 1.62}\n",
            "{'loss': 0.1247, 'grad_norm': 0.2022169977426529, 'learning_rate': 8.91686460807601e-06, 'epoch': 1.66}\n",
            "{'loss': 0.1245, 'grad_norm': 0.18467386066913605, 'learning_rate': 8.600158353127474e-06, 'epoch': 1.71}\n",
            "{'loss': 0.1056, 'grad_norm': 0.5879786014556885, 'learning_rate': 8.28345209817894e-06, 'epoch': 1.76}\n",
            "{'loss': 0.1253, 'grad_norm': 6.917881011962891, 'learning_rate': 7.966745843230404e-06, 'epoch': 1.81}\n",
            "{'loss': 0.1183, 'grad_norm': 0.12155551463365555, 'learning_rate': 7.65003958828187e-06, 'epoch': 1.85}\n",
            "{'loss': 0.1281, 'grad_norm': 2.4663872718811035, 'learning_rate': 7.333333333333333e-06, 'epoch': 1.9}\n",
            "{'loss': 0.1203, 'grad_norm': 9.349700927734375, 'learning_rate': 7.016627078384799e-06, 'epoch': 1.95}\n",
            "{'loss': 0.1175, 'grad_norm': 0.815051794052124, 'learning_rate': 6.699920823436263e-06, 'epoch': 2.0}\n",
            " 67% 8420/12630 [10:06<05:54, 11.88it/s]\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 21% 3/14 [00:00<00:00, 29.20it/s]\u001b[A\n",
            " 43% 6/14 [00:00<00:00, 23.91it/s]\u001b[A\n",
            " 64% 9/14 [00:00<00:00, 23.69it/s]\u001b[A\n",
            "                                        \n",
            "\u001b[A{'eval_loss': 0.3417024612426758, 'eval_accuracy': 0.908256880733945, 'eval_f1_macro': 0.9080634278002699, 'eval_runtime': 1.0951, 'eval_samples_per_second': 796.244, 'eval_steps_per_second': 12.784, 'epoch': 2.0}\n",
            " 67% 8420/12630 [10:07<05:54, 11.88it/s]\n",
            "100% 14/14 [00:01<00:00, 23.19it/s]\u001b[A\n",
            "{'loss': 0.0802, 'grad_norm': 7.256341457366943, 'learning_rate': 6.383214568487728e-06, 'epoch': 2.04}\n",
            "{'loss': 0.0726, 'grad_norm': 0.2532675564289093, 'learning_rate': 6.0665083135391935e-06, 'epoch': 2.09}\n",
            "{'loss': 0.0669, 'grad_norm': 0.1638599932193756, 'learning_rate': 5.749802058590658e-06, 'epoch': 2.14}\n",
            "{'loss': 0.0732, 'grad_norm': 15.354656219482422, 'learning_rate': 5.433095803642122e-06, 'epoch': 2.19}\n",
            "{'loss': 0.062, 'grad_norm': 5.019675254821777, 'learning_rate': 5.116389548693587e-06, 'epoch': 2.23}\n",
            "{'loss': 0.0665, 'grad_norm': 0.013684337958693504, 'learning_rate': 4.799683293745051e-06, 'epoch': 2.28}\n",
            "{'loss': 0.0866, 'grad_norm': 11.386571884155273, 'learning_rate': 4.482977038796517e-06, 'epoch': 2.33}\n",
            "{'loss': 0.083, 'grad_norm': 5.504183769226074, 'learning_rate': 4.1662707838479814e-06, 'epoch': 2.38}\n",
            "{'loss': 0.0772, 'grad_norm': 0.07586681842803955, 'learning_rate': 3.849564528899446e-06, 'epoch': 2.42}\n",
            "{'loss': 0.0687, 'grad_norm': 22.52975845336914, 'learning_rate': 3.5328582739509108e-06, 'epoch': 2.47}\n",
            "{'loss': 0.0698, 'grad_norm': 13.484916687011719, 'learning_rate': 3.2161520190023754e-06, 'epoch': 2.52}\n",
            "{'loss': 0.0785, 'grad_norm': 0.8931304216384888, 'learning_rate': 2.8994457640538405e-06, 'epoch': 2.57}\n",
            "{'loss': 0.0826, 'grad_norm': 0.46695998311042786, 'learning_rate': 2.5827395091053047e-06, 'epoch': 2.61}\n",
            "{'loss': 0.0863, 'grad_norm': 11.980164527893066, 'learning_rate': 2.26603325415677e-06, 'epoch': 2.66}\n",
            "{'loss': 0.0662, 'grad_norm': 0.15283970534801483, 'learning_rate': 1.9493269992082345e-06, 'epoch': 2.71}\n",
            "{'loss': 0.0761, 'grad_norm': 0.03137508034706116, 'learning_rate': 1.6326207442596992e-06, 'epoch': 2.76}\n",
            "{'loss': 0.0679, 'grad_norm': 37.59993362426758, 'learning_rate': 1.3159144893111638e-06, 'epoch': 2.8}\n",
            "{'loss': 0.0821, 'grad_norm': 0.042742520570755005, 'learning_rate': 9.992082343626287e-07, 'epoch': 2.85}\n",
            "{'loss': 0.0621, 'grad_norm': 4.027544975280762, 'learning_rate': 6.825019794140935e-07, 'epoch': 2.9}\n",
            "{'loss': 0.0703, 'grad_norm': 0.5787017941474915, 'learning_rate': 3.657957244655582e-07, 'epoch': 2.95}\n",
            "{'loss': 0.0786, 'grad_norm': 3.793088436126709, 'learning_rate': 4.9089469517022966e-08, 'epoch': 2.99}\n",
            "100% 12629/12630 [15:12<00:00, 14.50it/s]\n",
            "  0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 4/14 [00:00<00:00, 28.07it/s]\u001b[A\n",
            " 50% 7/14 [00:00<00:00, 24.71it/s]\u001b[A\n",
            " 71% 10/14 [00:00<00:00, 24.33it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.38156023621559143, 'eval_accuracy': 0.9208715596330275, 'eval_f1_macro': 0.9208164715636535, 'eval_runtime': 1.1109, 'eval_samples_per_second': 784.952, 'eval_steps_per_second': 12.602, 'epoch': 3.0}\n",
            "100% 12630/12630 [15:13<00:00, 14.50it/s]\n",
            "100% 14/14 [00:01<00:00, 23.86it/s]\u001b[A\n",
            "{'train_runtime': 919.4733, 'train_samples_per_second': 219.742, 'train_steps_per_second': 13.736, 'train_loss': 0.13879325708886128, 'epoch': 3.0}\n",
            "100% 12630/12630 [15:19<00:00, 13.74it/s]\n",
            "100% 14/14 [00:01<00:00, 13.06it/s]\n",
            "\n",
            "üìä Validation Metrics: {'eval_loss': 0.38156023621559143, 'eval_accuracy': 0.9208715596330275, 'eval_f1_macro': 0.9208164715636535, 'eval_runtime': 1.1443, 'eval_samples_per_second': 762.064, 'eval_steps_per_second': 12.235, 'epoch': 3.0}\n",
            "‚úÖ Model saved at: ./sst2_outputs/20251030-225910/best_model\n",
            "100% 14/14 [00:01<00:00, 13.38it/s]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9264    0.9112    0.9187       428\n",
            "           1     0.9157    0.9302    0.9229       444\n",
            "\n",
            "    accuracy                         0.9209       872\n",
            "   macro avg     0.9211    0.9207    0.9208       872\n",
            "weighted avg     0.9210    0.9209    0.9209       872\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[390  38]\n",
            " [ 31 413]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to check training status\n",
        "import os\n",
        "import glob\n",
        "\n",
        "out_dir = \"./sst2_outputs\"\n",
        "print(\"üìÅ Checking training folder...\")\n",
        "\n",
        "if os.path.exists(out_dir):\n",
        "    files = glob.glob(os.path.join(out_dir, \"**\", \"*\"), recursive=True)\n",
        "    if files:\n",
        "        print(\"‚úÖ Training folder exists with files:\")\n",
        "        for f in files[:10]:  # Show first 10 files\n",
        "            print(f\"  - {f}\")\n",
        "    else:\n",
        "        print(\"üìÅ Folder exists but empty - training in progress\")\n",
        "else:\n",
        "    print(\"‚ùå No training folder - training not started or in progress\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJxhuEgqZx9O",
        "outputId": "d17efab5-7c49-4abc-c13e-02a50d185858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Checking training folder...\n",
            "‚úÖ Training folder exists with files:\n",
            "  - ./sst2_outputs/20251030-222650\n",
            "  - ./sst2_outputs/20251030-225910\n",
            "  - ./sst2_outputs/20251030-225113\n",
            "  - ./sst2_outputs/logs\n",
            "  - ./sst2_outputs/20251030-222650/checkpoint-8420\n",
            "  - ./sst2_outputs/20251030-222650/checkpoint-4210\n",
            "  - ./sst2_outputs/20251030-222650/checkpoint-12630\n",
            "  - ./sst2_outputs/20251030-222650/best_model\n",
            "  - ./sst2_outputs/20251030-222650/checkpoint-8420/model.safetensors\n",
            "  - ./sst2_outputs/20251030-222650/checkpoint-8420/scaler.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PASTE THIS IN A NEW CELL - UPDATED VERSION\n",
        "\n",
        "import os, glob, torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(\"üöÄ RUNNING EVALUATION...\")\n",
        "\n",
        "# ====== 1Ô∏è‚É£ Locate Best Model Folder ======\n",
        "out_dir = \"./sst2_outputs\"\n",
        "\n",
        "# Look for BOTH file types\n",
        "candidates_bin = glob.glob(os.path.join(out_dir, \"**\", \"pytorch_model.bin\"), recursive=True)\n",
        "candidates_safe = glob.glob(os.path.join(out_dir, \"**\", \"model.safetensors\"), recursive=True)\n",
        "candidates = candidates_bin + candidates_safe\n",
        "\n",
        "if not candidates:\n",
        "    raise ValueError(\"‚ùå No trained model checkpoint found!\")\n",
        "\n",
        "best_model_path = max(candidates, key=os.path.getmtime)\n",
        "best_dir = os.path.dirname(best_model_path)\n",
        "print(f\"‚úÖ Using best checkpoint: {best_dir}\")\n",
        "\n",
        "# ====== 2Ô∏è‚É£ Load Model + Tokenizer ======\n",
        "tokenizer = BertTokenizer.from_pretrained(best_dir)\n",
        "model = BertForSequenceClassification.from_pretrained(best_dir)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# ====== 3Ô∏è‚É£ Evaluate ======\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "test_data = dataset[\"validation\"]\n",
        "\n",
        "def tokenize_fn(example):\n",
        "    return tokenizer(example[\"sentence\"], truncation=True, padding=\"max_length\", max_length=128)\n",
        "\n",
        "test_data = test_data.map(tokenize_fn, batched=True)\n",
        "test_data.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "test_loader = DataLoader(test_data, batch_size=32)\n",
        "\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"label\"].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = outputs.logits.argmax(dim=-1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"\\nüéØ FINAL ACCURACY: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "656463f343f84978a56d2d110e2bcc70",
            "2408b16bd895429a8f01922765589f49",
            "ad9332ddfccb4a01b8c22dd57c6d83eb",
            "9243da87250d4c8bbe6fee3449c53813",
            "61a180e874cb482c8054e04290f0d589",
            "6f3ea241d9df48bba640cb3e71f220a7",
            "9f3d721d83f74f399e9f4afe47b4ab74",
            "63f55f84b9a746b092e2c3583ac76a70",
            "a15799368302445489ae4f71af19c53e",
            "122f072d3cba4a4e99d98e9f1139599a",
            "8a710cc736da45c08db5e542976bc9ce"
          ]
        },
        "id": "vy1mPysVaOzo",
        "outputId": "0539cf9a-0a11-4223-a40d-fdfbd8bd2f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ RUNNING EVALUATION...\n",
            "‚úÖ Using best checkpoint: ./sst2_outputs/20251030-225910/best_model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "656463f343f84978a56d2d110e2bcc70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:05<00:00,  5.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üéØ FINAL ACCURACY: 92.09%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}